import type { Handler } from "@netlify/functions";
import fetch from "node-fetch";

//ì¸í„°í˜ì´ìŠ¤
interface ImageRequestBody {
  description: string; // story ë‚´ìš©
}

interface ImageResponse {
  imageUrl: string;
  summary?: string;
}

interface ErrorResponse {
  error: string;
}

// GPT Chat Completion ì‘ë‹µ íƒ€ì… (ê°„ë‹¨íˆ)
interface ChatCompletionResponse {
  choices: {
    message: {
      content: string;
    };
  }[];
}

const forbiddenWords = ["í­ë ¥", "ì´", "ì£½ìŒ", "ì‚´ì¸", "ì„±ì ", "ìŒë€", "í…ŒëŸ¬"];

// ê¸ˆì§€ ë‹¨ì–´ ì œê±° í•¨ìˆ˜
function sanitizeText(text: string): string {
  let sanitized = text;
  forbiddenWords.forEach((word) => {
    const regex = new RegExp(word, "gi");
    sanitized = sanitized.replace(regex, "");
  });
  return sanitized;
}

// ==== ì„¤ì • ìƒìˆ˜ ====
const SUMMARIZE_THRESHOLD = 1000; // ì›ë˜ ì²´í¬í•˜ë˜ ì„ê³„ê°’ (ë³´ë¥˜ìš©)
const CHUNK_SIZE = 3500; // chat modelì— ë³´ë‚¼ ì²­í¬ í¬ê¸° (ë¬¸ì ë‹¨ìœ„)
const FINAL_PROMPT_MAX = 900; // ì´ë¯¸ì§€ APIì— ë³´ë‚¼ ìµœì¢… í”„ë¡¬í”„íŠ¸ ìµœëŒ€ ê¸¸ì´
const MODEL = "gpt-4o-mini"; // ì‚¬ìš© ëª¨ë¸

// =======================
// ğŸ”¹ ê¸´ ìŠ¤í† ë¦¬ ìš”ì•½ í•¨ìˆ˜ (ê°œì„ ë¨ â€” ì—ëŸ¬ í•¸ë“¤ë§ í¬í•¨)
// =======================
async function summarizeText(text: string): Promise<string> {
  try {
    const res = await fetch("https://api.openai.com/v1/chat/completions", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        model: MODEL,
        messages: [
          {
            role: "system",
            content:
              "You are a helpful assistant that summarizes long children's stories in a kind and simple tone.",
          },
          {
            role: "user",
            content: `Summarize this story in one short paragraph under 500 characters:\n\n${text}`,
          },
        ],
        max_tokens: 400, // ì•ˆì „ì¥ì¹˜
      }),
    });

    if (!res.ok) {
      const txt = await res.text();
      console.error("summarizeText - OpenAI error:", res.status, txt);
      // í´ë°±: ì•ë¶€ë¶„ì„ ì˜ë¼ì„œ ë°˜í™˜
      return text.slice(0, 500);
    }

    const data = (await res.json()) as ChatCompletionResponse;
    const summary = data?.choices?.[0]?.message?.content?.trim();
    return summary || text.slice(0, 500);
  } catch (err: any) {
    console.error("summarizeText - Exception:", err);
    return text.slice(0, 500); // í´ë°±
  }
}

// =======================
// ğŸ”¹ ê¸´ í…ìŠ¤íŠ¸ ì•ˆì „í•˜ê²Œ ìš”ì•½/ì¤€ë¹„ (ì²­í¬ ìš”ì•½ -> í†µí•© ìš”ì•½)
// =======================
async function safePreparePrompt(text: string): Promise<{ finalPrompt: string; summary?: string }> {
  // ì´ë¯¸ ì§§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
  if (text.length <= SUMMARIZE_THRESHOLD) {
    const final = text.slice(0, FINAL_PROMPT_MAX);
    return { finalPrompt: final, summary: undefined };
  }

  // 1) í…ìŠ¤íŠ¸ ì²­í¬í™”
  const chunks: string[] = [];
  for (let i = 0; i < text.length; i += CHUNK_SIZE) {
    chunks.push(text.slice(i, i + CHUNK_SIZE));
  }

  // 2) ê° ì²­í¬ ìš”ì•½ (ë³‘ë ¬ë¡œ ì²˜ë¦¬í•´ë„ ë˜ì§€ë§Œ, rate-limit ê³ ë ¤í•´ ìˆœì°¨ ì²˜ë¦¬)
  const chunkSummaries: string[] = [];
  for (const chunk of chunks) {
    // summarizeText ë‚´ë¶€ì—ì„œ ì‹¤íŒ¨ ì‹œ ì•ˆì „ í´ë°±ì„ ë°˜í™˜í•¨
    const s = await summarizeText(chunk);
    chunkSummaries.push(s);
  }

  // 3) ìš”ì•½ë“¤ì„ í•©ì³ì„œ í•„ìš”í•˜ë©´ ì¬ìš”ì•½
  let combined = chunkSummaries.join(" ");
  if (combined.length > CHUNK_SIZE) {
    // í•œ ë²ˆ ë” ìš”ì•½ ì‹œë„ (ë” ì§§ì€ ê²°ê³¼ ê¸°ëŒ€)
    try {
      combined = await summarizeText(combined);
    } catch (e) {
      // í´ë°±: ì•ë¶€ë¶„ ì˜ë¼ì„œ ì‚¬ìš©
      combined = combined.slice(0, 1200);
    }
  }

  // finalPromptëŠ” ì´ë¯¸ì§€ API ì œí•œì„ ê³ ë ¤í•´ ì˜ë¼ë‘ 
  const finalPrompt = combined.slice(0, FINAL_PROMPT_MAX);

  return { finalPrompt, summary: combined };
}

// =======================
// ğŸ”¹ Netlify Handler (ìˆ˜ì •ë³¸)
// =======================
export const handler: Handler = async (event) => {
  if (!event.body)
    return { statusCode: 400, body: JSON.stringify({ error: "No body provided" }) };

  const { description } = JSON.parse(event.body) as ImageRequestBody;

  try {
    // 1ï¸âƒ£ ì…ë ¥ í…ìŠ¤íŠ¸ ì •ì œ
    const cleanDescription = sanitizeText(description || "");

    // 2ï¸âƒ£ ì•ˆì „í•˜ê²Œ í”„ë¡¬í”„íŠ¸ ì¤€ë¹„ (ìš”ì•½ í¬í•¨)
    const { finalPrompt, summary } = await safePreparePrompt(cleanDescription);

    // ë¡œê·¸: ì‹¤ì œ ì „ì†¡ë˜ëŠ” í”„ë¡¬í”„íŠ¸ ê¸¸ì´ í™•ì¸ìš©
    console.log("Prepared prompt length:", finalPrompt.length);

    // 3ï¸âƒ£ ì´ë¯¸ì§€ ìƒì„± ìš”ì²­ (í”„ë¡¬í”„íŠ¸ëŠ” ì§§ê²Œ ì˜ë¼ì„œ ë³´ëƒ„)
    const imageRes = await fetch("https://api.openai.com/v1/images/generations", {
      method: "POST",
      headers: {
        "Content-Type": "application/json",
        Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
      },
      body: JSON.stringify({
        prompt: `Create a cute, child-friendly illustration based on this story: "${finalPrompt}"`,
        size: "256x256",
      }),
    });

    if (!imageRes.ok) {
      const err = await imageRes.text();
      console.error("OpenAI Image Error:", imageRes.status, err);
      return { statusCode: 500, body: JSON.stringify({ error: `OpenAI Image Error: ${err}` }) };
    }

    const imageDataRaw: any = await imageRes.json();
    const imageUrl = imageDataRaw?.data?.[0]?.url;

    if (!imageUrl) {
      console.error("No image URL in response:", imageDataRaw);
      return { statusCode: 500, body: JSON.stringify({ error: "No image URL returned from OpenAI" }) };
    }

    // âœ… ë°˜í™˜
    const responseBody: ImageResponse = {
      imageUrl,
      summary: summary, // summaryê°€ undefinedì¼ ìˆ˜ë„ ìˆìŒ
    };

    return { statusCode: 200, body: JSON.stringify(responseBody) };

  } catch (error: any) {
    console.error("Server Error:", error);
    return { statusCode: 500, body: JSON.stringify({ error: `Server Error: ${error.message || error}` }) };
  }
};

export default handler;
